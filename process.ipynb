{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import signal, interpolate\n",
    "from scipy.signal import medfilt\n",
    "from statistics import median\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import os\n",
    "from classify import classify_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens the CSV file from the MAXM86161 Software\n",
    "def opencsv(name):\n",
    "    with open(name) as fp:\n",
    "        skip = next(filter(\n",
    "            lambda x: x[1].startswith('timestamp'),\n",
    "            enumerate(fp)\n",
    "        ))[0]\n",
    "    df = pd.read_csv(name, skiprows=skip)\n",
    "    df.drop(df.tail(4).index,\n",
    "            inplace = True)\n",
    "    df['timestamp']=df['timestamp'].astype(float).astype(int)\n",
    "    return df\n",
    "\n",
    "# 5th Order Butterworth Lowpass Filter Implementation\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, fs, cutoff, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "# 5th Order Butterworth Bandpass Filter Implementation \n",
    "def butter_bandpass(cutoff_l, cutoff_h, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = signal.butter(order, [cutoff_l/nyq, cutoff_h/nyq], btype='band', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, fs, cutoff_l, cutoff_h, order=5):\n",
    "    b, a = butter_bandpass(cutoff_l, cutoff_h, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "# Finds peaks in PPG and ECG signals\n",
    "def peakfind_ecg(x, distance=40, prominence=0.3):\n",
    "    peaks, _ = scipy.signal.find_peaks(x, distance=distance, prominence=prominence)\n",
    "    return peaks\n",
    "\n",
    "def peakfind_ppg(x, distance=40, prominence=200):\n",
    "    peaks, _ = scipy.signal.find_peaks(x, distance=distance, prominence=prominence)\n",
    "    return peaks\n",
    "\n",
    "# Aligns PPG signals from the wrist and finger\n",
    "def align_in_ref(p_in, p_ref, prom_ref=200, prom_in=200):\n",
    "    peaks_in = peakfind_ppg(p_in, prominence=prom_in)\n",
    "    peaks_ref = peakfind_ppg(p_ref, prominence=prom_ref)\n",
    "    anchor = peaks_in[1]\n",
    "    return min([pd - anchor for pd in peaks_ref], key=abs)\n",
    "\n",
    "# Removes spikes from the pressure sensor reading\n",
    "def remove_large_spikes(signal, threshold):\n",
    "    smoothed_signal = medfilt(signal, kernel_size=3)\n",
    "    spike_locations = np.abs(signal - smoothed_signal) > threshold\n",
    "    cleaned_signal = np.where(spike_locations, smoothed_signal, signal)\n",
    "\n",
    "    return cleaned_signal\n",
    "\n",
    "# Converts timestamp strings to a unix timestamp\n",
    "def convert_to_unix(timestamp_str, pattern, timezone_str='Asia/Singapore'):\n",
    "    timestamp_format = pattern\n",
    "    timestamp = datetime.strptime(timestamp_str, timestamp_format)\n",
    "    input_timezone = pytz.timezone(timezone_str)\n",
    "    timestamp = input_timezone.localize(timestamp)\n",
    "    singapore_timezone = pytz.timezone(\"Asia/Singapore\")\n",
    "    timestamp_singapore = timestamp.astimezone(singapore_timezone)\n",
    "    unix_timestamp = int(timestamp_singapore.timestamp())\n",
    "\n",
    "    return unix_timestamp\n",
    "\n",
    "# Aligns ECG and PPG signals\n",
    "def find_peak_shift(decg, dppg):\n",
    "    l=min(len(decg), len(dppg))\n",
    "    decg = decg[:l]\n",
    "    dppg = dppg[:l]\n",
    "    \n",
    "    r = dict()\n",
    "    cr, _ = scipy.stats.pearsonr(decg, dppg)\n",
    "    r.update({0: cr})\n",
    "    \n",
    "    for i in range(1, l//2):\n",
    "        cr, _ = scipy.stats.pearsonr(decg[i:], dppg[:-i])\n",
    "        r.update({i: cr})\n",
    "    for i in range(1, l//2):\n",
    "        cr, _ = scipy.stats.pearsonr(dppg[i:], decg[:-i])\n",
    "        r.update({-i: cr})\n",
    "    \n",
    "    return int(max(r, key=r.get))\n",
    "\n",
    "def reset_time(col, st, fact=1000):\n",
    "    return (col - st) / fact\n",
    "\n",
    "def get_prominence(p, fs):\n",
    "    bpfed = butter_bandpass_filter(p, fs, 0.8, 3.5)\n",
    "    bpfed -= min(bpfed)\n",
    "    \n",
    "    return median(bpfed)/3\n",
    "\n",
    "def subtract_ac(time, sig):\n",
    "    peaks = peakfind_ppg(sig, prominence=get_prominence(sig, 100)/100)\n",
    "    line = interpolate.CubicSpline(time[peaks], sig[peaks])\n",
    "    ac = (sig - line(time))*-1\n",
    "    return ac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_id = '1000'\n",
    "\n",
    "df_ppg_in = opencsv('raw_data/wrist_' + s_id +'.csv')\n",
    "df_ppg_ref = opencsv('raw_data/finger_' + s_id +'.csv')\n",
    "df_pressure = pd.read_csv('raw_data/pres_' + s_id +'.csv')\n",
    "df_ecg = pd.read_csv('raw_data/ecg_' + s_id + '.csv')\n",
    "df_spo2 = pd.read_csv('raw_data/spo2_' + s_id + '.csv')\n",
    "df_bp = pd.read_csv('raw_data/bp_' + s_id + '.csv')\n",
    "\n",
    "start = min(df_pressure['time'])\n",
    "\n",
    "df_ppg_in['timestamp']=reset_time(df_ppg_in['timestamp'], start)\n",
    "df_ppg_ref['timestamp']=reset_time(df_ppg_ref['timestamp'], start)\n",
    "\n",
    "df_ppg_in['PPG_G_LPF_10Hz'] = butter_lowpass_filter(df_ppg_in['LEDC1'], 128, 10)\n",
    "df_ppg_ref['PPG_G_LPF_10Hz'] = butter_lowpass_filter(df_ppg_ref['LEDC1'], 128, 10)\n",
    "\n",
    "df_ppg_in['PPG_IR_LPF_10Hz'] = butter_lowpass_filter(df_ppg_in['LEDC2'], 128, 10)\n",
    "df_ppg_ref['PPG_IR_LPF_10Hz'] = butter_lowpass_filter(df_ppg_ref['LEDC2'], 128, 10)\n",
    "\n",
    "df_ppg_in['PPG_R_LPF_10Hz'] = butter_lowpass_filter(df_ppg_in['LEDC3'], 128, 10)\n",
    "df_ppg_ref['PPG_R_LPF_10Hz'] = butter_lowpass_filter(df_ppg_ref['LEDC3'], 128, 10)\n",
    "\n",
    "df_pressure['time']=reset_time(df_pressure['time'], start)\n",
    "\n",
    "df_pressure['reading'] = remove_large_spikes(df_pressure['reading'], 400)\n",
    "df_pressure['reading'] = butter_lowpass_filter(df_pressure['reading'], 80, 8)\n",
    "\n",
    "df_ecg['time']/=1000000\n",
    "df_ecg['time']-=start\n",
    "df_ecg['time']/=1000\n",
    "\n",
    "df_spo2['Timestamp'] = df_spo2['Time'].apply(lambda x: convert_to_unix(x, \"%H:%M:%S %b %d %Y\"))\n",
    "df_bp['Timestamp'] = df_bp['Measurement Date'].apply(lambda x: convert_to_unix(x, \"%Y/%m/%d %H:%M\"))\n",
    "\n",
    "df_spo2['Timestamp'] -= start//1000\n",
    "df_bp['Timestamp'] -= start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPG-Pressure Synchronisation\n",
    "\n",
    "Squeezing the sensors together with the fingers causes spikes in the PPG and Pressure signals that can be used for alignment. \n",
    "\n",
    "These spikes are seen between 5s and 15s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 1)\n",
    "\n",
    "df_pressure.plot(x='time', y='reading', ax=axes[0])\n",
    "df_ppg_in.plot(x='timestamp', y='PPG_G_LPF_10Hz', ax=axes[1])\n",
    "df_ppg_ref.plot(x='timestamp', y='PPG_G_LPF_10Hz', ax=axes[2])\n",
    "\n",
    "limit_view_start = 0\n",
    "limit_view_end = 20\n",
    "\n",
    "df_pressure[df_pressure['time'].between(limit_view_start, limit_view_end)].plot(x='time', y='reading', ax=axes[3])\n",
    "df_ppg_in[df_ppg_in['timestamp'].between(limit_view_start, limit_view_end)].plot(x='timestamp', y='PPG_G_LPF_10Hz', ax=axes[4])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect two corresponding peaks and adjust the timestamps accordingly. \n",
    "\n",
    "Note that stable readings begin from around t=100s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1)\n",
    "\n",
    "df_pressure[df_pressure['time'].between(limit_view_start, limit_view_end)].plot(ax=axes[0], x='time', y='reading')\n",
    "h,l = axes[0].get_legend_handles_labels()\n",
    "axes[0].legend(h[:2], ['Pressure'], loc=2)\n",
    "axes[0] = axes[0].twinx()\n",
    "df_ppg_in[df_ppg_in['timestamp'].between(limit_view_start, limit_view_end)].plot(ax=axes[0], x='timestamp', y='PPG_G_LPF_10Hz', color=\"r\")\n",
    "axes[0].legend(['PPG'])\n",
    "\n",
    "pres_s = 8\n",
    "pres_e = 12\n",
    "ppg_s = 10\n",
    "ppg_e = 15\n",
    "\n",
    "pres_max = df_pressure[df_pressure['time'].between(pres_s, pres_e)]['reading'].idxmax()\n",
    "ppg_max = df_ppg_in[df_ppg_in['timestamp'].between(ppg_s, ppg_e)]['PPG_G_LPF_10Hz'].idxmax()\n",
    "\n",
    "print(df_pressure.loc[pres_max]['time'], df_ppg_in.loc[ppg_max]['timestamp'])\n",
    "correction = df_pressure.loc[pres_max]['time'] - df_ppg_in.loc[ppg_max]['timestamp']\n",
    "print(correction)\n",
    "df_ppg_in['timestamp'] += correction\n",
    "df_ppg_ref['timestamp'] += correction\n",
    "\n",
    "df_ecg['time'] += correction\n",
    "df_spo2['Timestamp'] += correction\n",
    "df_bp['Timestamp'] += correction\n",
    "\n",
    "axes[1] = df_pressure[df_pressure['time'].between(limit_view_start, limit_view_end)].plot(ax=axes[1],x='time', y='reading')\n",
    "h,l = axes[1].get_legend_handles_labels()\n",
    "axes[1].legend(h[:2], ['Pressure'], loc=2)\n",
    "axes[1] = axes[1].twinx()\n",
    "df_ppg_in[df_ppg_in['timestamp'].between(limit_view_start, limit_view_end)].plot(ax=axes[1], x='timestamp', y='PPG_G_LPF_10Hz', color=\"r\")\n",
    "axes[1].legend(['PPG'])\n",
    "\n",
    "df_ppg_look_4_start = df_ppg_in[df_ppg_in['timestamp'].between(limit_view_start, limit_view_start + 300)]\n",
    "axes[2].plot(df_ppg_look_4_start['timestamp'], df_ppg_look_4_start['PPG_G_LPF_10Hz'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPG-ECG Synchronisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select an arbitary segment of ECG and PPG signals without motion artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 1)\n",
    "\n",
    "df_ecg.plot(x='time', y='ecg', ax=axes[0])\n",
    "df_ppg_ref.plot(x='timestamp', y='PPG_G_LPF_10Hz', ax=axes[1])\n",
    "\n",
    "limit_view_start = 690\n",
    "limit_view_end = 725\n",
    "\n",
    "df_ecg[df_ecg['time'].between(limit_view_start, limit_view_end)].plot(x='time', y='ecg', ax=axes[2])\n",
    "df_ppg_ref[df_ppg_ref['timestamp'].between(limit_view_start, limit_view_end)].plot(x='timestamp', y='PPG_G_LPF_10Hz', ax=axes[3])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the selected segment, calculate the distances between adjacent peaks to align the PPG and ECG signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_section = df_ecg[df_ecg['time'].between(limit_view_start, limit_view_end)]\n",
    "ppg_section = df_ppg_ref[df_ppg_ref['timestamp'].between(limit_view_start, limit_view_end)]\n",
    "\n",
    "peaks_ecg = peakfind_ecg(ecg_section['ecg'])\n",
    "peaks_ppg = peakfind_ppg(ppg_section['PPG_G_LPF_10Hz'], prominence=500)\n",
    "\n",
    "dists_ecg = []\n",
    "for i in range(1, len(peaks_ecg)):\n",
    "    dists_ecg.append(peaks_ecg[i] - peaks_ecg[i-1])\n",
    "\n",
    "dists_ppg = []\n",
    "for i in range(1, len(peaks_ppg)):\n",
    "    dists_ppg.append(peaks_ppg[i] - peaks_ppg[i-1])\n",
    "\n",
    "to_shift = find_peak_shift(dists_ecg, dists_ppg)\n",
    "print('Shifting ECG signal backwards by', to_shift, 'cycles')\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(dists_ecg, color='r')\n",
    "plt.plot(dists_ppg, color='g')\n",
    "plt.legend([\"ECG Distances\", \"PPG Distances\"])\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "if to_shift >= 0:\n",
    "    plt.plot(dists_ecg, color='r')\n",
    "    plt.plot(([dists_ppg[0]]*abs(to_shift)) + dists_ppg, color='g')\n",
    "else:\n",
    "    plt.plot(([dists_ecg[0]]*abs(to_shift)) + dists_ecg, color='r')\n",
    "    plt.plot(dists_ppg, color='g')\n",
    "    \n",
    "plt.suptitle(\"ECG & PPG Distances Before and After Alignment\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the time between two peaks separated by the determined number of cycles and subtract it to align the signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_shift = ecg_section['time'].values[peaks_ecg[1 + abs(to_shift)]] - ppg_section['timestamp'].values[peaks_ppg[1]]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1)\n",
    "fig.set_size_inches(10, 3)\n",
    "fig.suptitle(\"ECG & PPG Before and After Alignment\")\n",
    "\n",
    "df_ecg[df_ecg['time'].between(limit_view_start, limit_view_start + 10)].plot(x='time', y='ecg', ax=axes[0])\n",
    "axes[0] = axes[0].twinx()\n",
    "df_ppg_ref[df_ppg_ref['timestamp'].between(limit_view_start, limit_view_start + 10)].plot(x='timestamp', y='PPG_G_LPF_10Hz', ax=axes[0], color='r')\n",
    "\n",
    "if time_shift >= 0:\n",
    "    df_ecg['time'] += time_shift\n",
    "else:\n",
    "    df_ecg['time'] -= time_shift\n",
    "\n",
    "df_ecg[df_ecg['time'].between(limit_view_start, limit_view_start + 10)].plot(x='time', y='ecg', ax=axes[1])\n",
    "axes[1] = axes[1].twinx()\n",
    "df_ppg_ref[df_ppg_ref['timestamp'].between(limit_view_start, limit_view_start + 10)].plot(x='timestamp', y='PPG_G_LPF_10Hz', ax=axes[1], color='r')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming and Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim each signal to the time period between the start of stable readings and the earliest end of recording on any device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the start of content\n",
    "start = 100\n",
    "\n",
    "end = min(max(df_ppg_in['timestamp']), max(df_ppg_ref['timestamp']), max(df_pressure['time']), max(df_ecg['time']), max(df_spo2['Timestamp']))\n",
    "\n",
    "df_ppg_in = df_ppg_in[df_ppg_in['timestamp'].between(start, end)].copy()\n",
    "df_ppg_ref = df_ppg_ref[df_ppg_ref['timestamp'].between(start, end)].copy()\n",
    "df_pressure = df_pressure[df_pressure['time'].between(start, end)].copy()\n",
    "df_ecg = df_ecg[df_ecg['time'].between(start, end)].copy()\n",
    "df_spo2 = df_spo2[df_spo2['Timestamp'].between(start, end)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample each trace to 100Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = int(len(df_ppg_in)*100/128)\n",
    "\n",
    "trim=100\n",
    "\n",
    "time = signal.resample(df_ppg_in['timestamp'], ln)[trim:-trim]\n",
    "\n",
    "ppg_in_g = signal.resample(df_ppg_in['PPG_G_LPF_10Hz'], ln)[trim:-trim]\n",
    "ppg_ref_g = signal.resample(df_ppg_ref['PPG_G_LPF_10Hz'], ln)[trim:-trim]\n",
    "\n",
    "ppg_in_ir = signal.resample(df_ppg_in['PPG_IR_LPF_10Hz'], ln)[trim:-trim]\n",
    "ppg_ref_ir = signal.resample(df_ppg_ref['PPG_IR_LPF_10Hz'], ln)[trim:-trim]\n",
    "\n",
    "ppg_in_r = signal.resample(df_ppg_in['PPG_R_LPF_10Hz'], ln)[trim:-trim]\n",
    "ppg_ref_r = signal.resample(df_ppg_ref['PPG_R_LPF_10Hz'], ln)[trim:-trim]\n",
    "\n",
    "pressure = signal.resample(df_pressure['reading'], ln)[trim:-trim]\n",
    "ecg = signal.resample(df_ecg['ecg'], ln)[trim:-trim]\n",
    "spo2 = signal.resample(df_spo2['Oxygen Level'], ln)[trim:-trim]\n",
    "\n",
    "df_final = pd.DataFrame(data={\\\n",
    "                              'Time': time,\\\n",
    "                              'PPG_In_G_LPF_10Hz': ppg_in_g,\\\n",
    "                              'PPG_In_IR_LPF_10Hz': ppg_in_ir,\\\n",
    "                              'PPG_In_R_LPF_10Hz': ppg_in_r,\\\n",
    "                              'PPG_Ref_G_LPF_10Hz': ppg_ref_g,\\\n",
    "                              'PPG_Ref_IR_LPF_10Hz': ppg_ref_ir,\\\n",
    "                              'PPG_Ref_R_LPF_10Hz': ppg_ref_r,\\\n",
    "                              'Pressure_In': pressure,\\\n",
    "                              'ECG': ecg,\\\n",
    "                              'SpO2': spo2\n",
    "                             })\n",
    "\n",
    "df_final.plot(x='Time', y='PPG_In_G_LPF_10Hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract relevant 4-minute windows and save the (mostly) raw signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = []\n",
    "\n",
    "idxs = [[120, 360], [510, 750], [1340, 1580], [1810, 2050], [2120, 2360], [2550, 2790]]\n",
    "\n",
    "fig, axes = plt.subplots(len(idxs), 1)\n",
    "\n",
    "for i, idx in enumerate(idxs):\n",
    "    a = idx[0]\n",
    "    b = idx[1]\n",
    "    small = df_final[df_final['Time'].between(a, b)].copy()\n",
    "    \n",
    "    small['BP_Sys'] = df_bp['SYS(mmHg)'].values[i]\n",
    "    small['BP_Dia'] = df_bp['DIA(mmHg)'].values[i]\n",
    "    \n",
    "    small.plot(ax=axes[i], x='Time', y='PPG_In_G_LPF_10Hz')\n",
    "\n",
    "    small['Time'] = np.sort(small['Time'].values)\n",
    "    \n",
    "    windows.append(small[['Time', 'PPG_In_G_LPF_10Hz', 'PPG_In_IR_LPF_10Hz', 'PPG_In_R_LPF_10Hz',\n",
    "           'PPG_Ref_G_LPF_10Hz', 'PPG_Ref_IR_LPF_10Hz', 'PPG_Ref_R_LPF_10Hz', \n",
    "           'Pressure_In', 'ECG', 'BP_Sys', 'BP_Dia', 'SpO2']].copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract AC Component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the AC component from each window by identifying waveform feet, fitting a cubic spline through them and subtracting the resulting spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "\n",
    "for window in windows:\n",
    "    # Removing the AC Component\n",
    "    window['PPG_In_G_AC'] = subtract_ac(window['Time'].values, window['PPG_In_G_LPF_10Hz'].values)\n",
    "\n",
    "    window['PPG_Ref_G_AC'] = subtract_ac(window['Time'].values, window['PPG_Ref_G_LPF_10Hz'].values)\n",
    "    window['PPG_Ref_IR_AC'] = subtract_ac(window['Time'].values, window['PPG_Ref_IR_LPF_10Hz'].values)\n",
    "    window['PPG_Ref_R_AC'] = subtract_ac(window['Time'].values, window['PPG_Ref_R_LPF_10Hz'].values)\n",
    "    \n",
    "    window.to_csv('processed/' + str(i) + '_preprocessed_' + s_id + '.csv')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 40\n",
    "\n",
    "for file_idx, window in enumerate(windows):\n",
    "    data_in = window['PPG_In_G_AC'].values\n",
    "    data_ref = window['PPG_Ref_G_AC'].values\n",
    "    pres_in = window['Pressure_In'].values\n",
    "    \n",
    "    save_idxs = []\n",
    "    \n",
    "    peaks_in = peakfind_ppg(-data_in, prominence=get_prominence(data_in, 100)/100)\n",
    "    peaks_ref = peakfind_ppg(-data_ref, prominence = np.median(data_ref)*1.5)\n",
    "    \n",
    "    max_in = len(peaks_in)\n",
    "    max_ref = len(peaks_ref)\n",
    "    \n",
    "    i_in = 0\n",
    "    i_ref = 0\n",
    "\n",
    "    \n",
    "    while i_in < max_in - 1 and i_ref < max_ref - 1:\n",
    "        while (i_ref < max_ref - 1 and peaks_ref[i_ref+1] - peaks_ref[i_ref] >= 110) or peaks_in[i_in] - peaks_ref[i_ref] > 40:\n",
    "            i_ref += 1\n",
    "            \n",
    "        while (i_in < max_in - 1 and peaks_in[i_in+1] - peaks_in[i_in] >= 110) or peaks_in[i_in] - peaks_ref[i_ref] < -40:\n",
    "            i_in += 1\n",
    "            \n",
    "        if i_in < max_in - 1 and i_ref < max_ref - 1:\n",
    "            if data_in[peaks_in[i_in]] < t and data_in[peaks_in[i_in]] > -t and data_ref[peaks_ref[i_ref+1]] < t and data_ref[peaks_ref[i_ref+1]] > -t:\n",
    "                peak_ref = data_ref[peaks_ref[i_ref]:peaks_ref[i_ref+1]]\n",
    "                peak_in = data_in[peaks_in[i_in]:peaks_in[i_in+1]]\n",
    "                \n",
    "                in_t = classify_smooth(peak_in)\n",
    "                ref_t = classify_smooth(peak_ref)\n",
    "\n",
    "                save_idxs.append([peaks_ref[i_ref], peaks_ref[i_ref+1], peaks_in[i_in], peaks_in[i_in+1], in_t, ref_t])\n",
    "\n",
    "                \n",
    "        i_ref+=1\n",
    "        i_in+=1\n",
    "        \n",
    "    df_idxs=pd.DataFrame(data=save_idxs, columns=['ref_s', 'ref_e', 'in_s', 'in_e', 'in_t', 'ref_t'])\n",
    "    df_idxs.to_csv('processed/' + str(file_idx) + '_indices_' + s_id + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [file for file in os.listdir(\"processed/\") if 'preprocessed' in file and file.endswith('.csv')]\n",
    "csv_files.sort()\n",
    "\n",
    "i=0\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(\"processed/\" + csv_file)[10000:15000]\n",
    "\n",
    "    plt.figure(figsize=(48,6))\n",
    "    plt.plot(df['PPG_In_G_AC']*25, color='r')\n",
    "    plt.plot(df['PPG_Ref_G_AC']*10, color='g')\n",
    "    plt.plot(df['ECG']*1000, color='blue')\n",
    "    plt.title(csv_file)\n",
    "\n",
    "    print('Sys BP', df['BP_Sys'].values[0], 'Dia BP', df['BP_Dia'].values[0])\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
